# 感知融合中的深度学习
## 1.概述 
环境感知是自动驾驶的先决条件。
将智能驾驶感知的上游，下游工作罗列一下大致分为一下几步。
传感器底层信号处理，上层信号处理，目标追踪，轨迹预测，行为决策，和路线规划。

![text](/img/dem.gif)

深度学习主要应用于传统不易解决的问题。如目标识别，态势预估
和行为决策。
目标识别：是目前在最广泛的应用的领域，已经有成熟的工程化产品如果mobileye通过摄像头进行目标检测。
态势预估：用于目标航迹的预测，例如在十字路口预测车辆行直行转弯。因为要处理时序信号所以要用到递归神经网(RNN）
行为决策：难点问题，在复杂条件下决策，如路上听着一辆双闪的车，因该从旁边绕开。传统finite state machine复杂场景下复杂度很高。深度强化学习（DRL）可以处理复杂的场景关系，是目前的研究热点。

## 2. 深度学习简介 
### 2.1 感知器
神经网络是由神经元组成的。
受仿生学启发神经元可以由感知器来建模。
感知器组成包括输入x，权重w，激励函数，输出y
如果已知x,w,求y，为正向传播，用于预测过程。
如果知己y，x，求w, 为反向传播，用于网络的训练过程。
单个感知器可以用于简单的分类问题。
例如：
输入x，表示影响分类的不同特征
权重w, 表示每个特征对输出结果的影响大小
求和之后通入激励函数，如果值如果高于某阈值则出发输出y，反之则不触发。

### 2.2 多层神经网络
单个感知器只能线性分割问题（用直线画出分割线）。
如果需要对复杂的非线性问题进行分类，则需要采用多层神经网络，将上一层感知器的输出作为下一层网络的输入。
单层网络只能做到线性逼近，如果采用多层网络，则可以通过“降维打击”的方法将输入映射到高维空间，这样就能通过线性平面进行分割了。

### 2.3 全连接网络
神经网络的本质是函数逼近。通过多层网络可以解决负载的分类问题。
例如对手写字体的分类。将每个像素作为输入连接到神经网络的输入，网络每一层之间为完全连接，最后一层输出层为10个神经元感知器代表0到9，10个数字。

### 2.4 局部连接网络
但是全连接网络有个致命的缺点就是参数巨大，导致所需计算和存储资源过多。
例如，一个1000x1000像素的图片，中间隐藏层有100个感知器，就需要1000x1000x100 = 10^8(100M)个参数。

如果神经元间不采用全连接，而是采用局部连接，则可以利用图片的空间性质来减少模型的参数。例如如果要识别人脸，人脸的特征在空间上是上是相邻的。眼睛和鼻子嘴巴不会相隔的太远。所以不需要将与其距离很远的像素输入。

如果将前个1000x1000像素的图片输入局部连接网络，每个神经元只与一块10x10像素的区域相连，区域间无覆盖，中间隐藏层还是100个感知器，那么局部连接层的参数只有 10*10*100 = 10^4（10K），比100M的参数量有了很大的缩减。

我们还可以通过参数共享的方法进一步缩减模型的大小。因为在图片的不同区域寻找的特征是相同的，则可以让中间层采用相同的参数。这样我们10*10*1 = 10^2
通过局部连接和参数共享比全连接的参数量有了极大的缩减。

### 2.5 卷积神经网络

卷积的作用是特征提取。通过核函数小块与图像小块区域的相乘相加来特征提取。如果不进行像素翻转则成为互相关，如果翻转则称为卷积。在特征提取方面，卷积和互相关的功能是类似的。

卷积网络也是受生物视网膜结构的启发。

卷积层的特点在于自动提取特征。底层特征为基本特征如边缘检测，中间层是局部特征，上层特征为高级特征。
如人脸检测中底层会检测到边沿，中层会检测到人的眼睛鼻子，上层像会检测到类似鬼脸的人脸特征。

## 3. 感知中的应用

### 3.1 目标检测
目前深度学习在自动驾驶感知中最重要的应用。
目标检测与图片分类不同之处在于，目标检测不仅要识别图片中有什么物体，还要确定目标的位置并用bounding box框出来。
这需要训练两个模型，一个classifer用于目标分类，一个regresser用于框出bounding box。
实现目标检测的方法有许多，其中主流的有r-cnn, fast-cnn, yolo。
因为目标检测算法需要用在在线检测中，所以识别的精度和速度都很重要。
传统的滑窗方法先建立位置大小不同的窗口，再再每个窗口中运行目标分类。而这些方法只需运行一次神经网络的运算，在feature map中找出可能包含目标的区域。
在初步识别之后，结果中会出现重复区域，需要用到nonmax supression将重复区域删除。
首先找到最可能包含目标的边框，然后计算最可能边框与其他边框的IOU（Intersection over Uniion）, IOU的值越大表示重复区域越多。最后滤除IOU小于阈值的边框就得到最终的边框。

### 3.2 语义分割

语义分割的目的是对图像进行像素级的分类。
图像的原始像素信息并不能告诉我们图片里是什么，所以语义分割的为了提取图片里信息的含义。
语义分割可以通过全卷积网络来实现（FCNN）。它与一般网图片分类网络不同的地方在于，分类网络最后一层是全连接层，语义分割网络是全卷积层。在feature map的层级就能进行分类。最后在通过卷积网络把分类结果向上映射到每个像素。
语义分割在自动驾驶的主要应用可行使区域和车道线识别现实中的车道线有不清晰，虚线，阴影。可以通过语义分割先将可行驶区域划分出来再进行做车道线识别。

### 3.3 传感器融合
摄像头的最大缺陷对深度的信息不是通过测量而是通过推测出来的。
摄像头虽然可以得到深度信息，但在特定的场景下会不准确。
而自动驾驶对安全的要求极高。其对性能的限制是以其最差情况为准。
因此最好的办法是扬长避短。将摄像头目标识别的优势与激光雷达、毫米波雷达测距，测速的优势结合起来。
具体方案可将，激光雷达的在三维坐标系中的点云投影到图像的二维平面上。
通过目标识别产生bounding box。再将bounding box内的点云与图像匹配生成目标。目标的类型由图像获得，目标的位置由激光雷达获得。最后再将目标与毫米波雷达进行匹配，获得速度信息。
因为毫米波雷达信号较为稀疏，所以采用目标级融合就可以。
而图像和激光雷达信号稠密，所以采用信号级融合。

## 4. 模型工程化

从模型训练到在控制器上移植，一般需要选择主干网络，修改上层网络， 准备实验数据，模型训练，工程化移植，验证等六个步骤。

### 4.1 选择主干网络
第一步是根据要解决的问题选择主干网络。主干网络的目的是特征提取。
从神经网络的发展来看，
从12年8层的AlexNet，到14年22层的GoogLeNet，再到15年152层的ResNet,主干网络有层数增加的趋势。
但选择主干网络并不是层数越高越好。其中存在这性能与计算时间的有权衡关系。
如下图所示，精度越高的网络往往所需要的计算量也越大。
自动驾驶很多时候需要实时运算，所以可以选择像MobileNet这样计算量小性能又不错的网络结构。

### 4.2 修改上层网络
选择好主干网络后，第二部是更改上层网络。
底层网络训练得到的结果可以共用，底层特征类似。好处可以用少量数据就能训练，因为80% 的工作在底层特征，提高训练速度，减少训练数据。
例如，在pytorch中可以用选择主干网络。在model zoo 上可以下载训练过的网络。
如原来的网络在有40类，现在想做个只有6类的classifier，则将顶层改为6个，再用新数据集训练  

### 4.3 准备训练数据 

接下来是准备训练数据。神经网络需要大量数据。如果自采的数据不足有以下办法可以采用。
公开数据，自动驾驶相关的数据有有Kitti, cityscape,nuscence, waymo等。采用公开数据的时候需要注意一些问题，如特殊场景，国内特有道路，工况等。和一些先验知识，像行车时一般是第一视角结构化道路。数据不足时也可采用数据扩充data augmentaion。但需要注意不好数据会降低模型精度。

### 4.4 工程化移植
从模型原型到最总在控制器上运行，中间需要大量工作，这就体现到生态的重要性。社区活跃的生态，如果有问题，可以太网上找到解答。
例如Nvida，就提供模型移植和优化工具tensorRT,
用python训练的模型转为通用的onnx结构后用tensorRT对并行计算进行优化,再移植到GPU上。

### 4.5 感知架构设计
深度学习在感知中有广泛的应用，如目标，车道线，红路灯的检测，车辆行人行为的预测等都可以用通过神经网络来实现。
在设计架构时应考虑模块的并行。
通过让子模块承担独立任务, 减少模块间通信来提高并行。
子模块内部可以用深度学习（黑盒模型）来实现。通过大量数据充分验证其安全性。
再把子模块的结果通入顶层模块作为仲裁。顶层模块采用相对简单的白盒模型，便于理解和与其他团队沟通。

## 5. 总结
深度神经网络模型训练是一个系统工程。需要一套从模型设计，部署，验证，到数据采集的闭环的pipeline。在开发过程中可以
只用20%的时间模型修改，而80%时间则用于工具链的建立。