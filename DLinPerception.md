# 感知融合中的深度学习
## 1.概述 
环境感知是自动驾驶的先决条件。
将智能驾驶感知的上游，下游工作罗列一下大致分为一下几步。
传感器底层信号处理，
上层信号处理，
目标追踪
![text](/img/alice.jpg)
深度学习主要应用于传统不易解决的问题。
目标识别
态势预估
行为决策
目标识别是目前在最广泛的应用的领域，工程化成熟，可以
用到深度下学习
态势预估，目标航迹的预测，如在十字路口预测车辆行直行转弯，
行为决策：难点问题，在复杂条件下决策，如路上听着一辆双闪的车，因该从旁边绕开。传统finite state machine复杂场景下复杂度很高

## 2. 深度学习简介 
### 2.1 感知器
神经网络是由神经元组成的。
受仿生学启发神经元可以由感知器来建模。
感知器组成包括输入x，权重w，激励函数，输出y
如果已知x,w,求y，为正向传播，用于预测过程。
如果知己y，x，求w, 为反向传播，用于网络的训练过程。
单个感知器可以用于简单的分类问题。
例如：
输入x，表示影响分类的不同特征
权重w, 表示每个特征对输出结果的影响大小
求和之后通入激励函数，如果值如果高于某阈值则出发输出y，反之则不触发。

### 2.2 多层神经网络
单个感知器只能线性分割问题（用直线画出分割线）。
如果需要对复杂的非线性问题进行分类，则需要采用多层神经网络，将上一层感知器的输出作为下一层网络的输入。
单层网络只能做到线性逼近，如果采用多层网络，则可以通过“降维打击”的方法将输入映射到高维空间，这样就能通过线性平面进行分割了。

### 2.3 全连接网络
神经网络的本质是函数逼近。通过多层网络可以解决负载的分类问题。
例如对手写字体的分类。将每个像素作为输入连接到神经网络的输入，网络每一层之间为完全连接，最后一层输出层为10个神经元感知器代表0到9，10个数字。

### 2.4 局部连接网络
但是全连接网络有个致命的缺点就是参数巨大，导致所需计算和存储资源过多。
例如，一个1000x1000像素的图片，中间隐藏层有100个感知器，就需要1000x1000x100 = 10^8(100M)个参数。

如果神经元间不采用全连接，而是采用局部连接，则可以利用图片的空间性质来减少模型的参数。例如如果要识别人脸，人脸的特征在空间上是上是相邻的。眼睛和鼻子嘴巴不会相隔的太远。所以不需要将与其距离很远的像素输入。

如果将前个1000x1000像素的图片输入局部连接网络，每个神经元只与一块10x10像素的区域相连，区域间无覆盖，中间隐藏层还是100个感知器，那么局部连接层的参数只有 10*10*100 = 10^4（10K），比100M的参数量有了很大的缩减。

我们还可以通过参数共享的方法进一步缩减模型的大小。因为在图片的不同区域寻找的特征是相同的，则可以让中间层采用相同的参数。这样我们10*10*1 = 10^2
通过局部连接和参数共享比全连接的参数量有了极大的缩减。

### 2.5 卷积神经网络

卷积的作用是特征提取。小块区域和图片扫，用于特征提取，相乘相加，如果如进行翻转互相关，如果翻转卷积。
在特征提取方面，卷积和互相关的功能是类似的，习惯称为卷积。
局部连接网络的示意图，输入与空间上相邻的输入。
受生物视网膜结构的启发。
卷积层自动提取特征，底层提取基本的，如线检测，中间层是局部特征，
底层线特征，中层， 人脸眼睛鼻子，车轮子车窗，高层像鬼脸
应用

## 3. 感知中的应用
### 3.1 目标检测
目前深度学习在自动驾驶感知中最重要的应用。
目标检测与图片分类不同之处在于，目标检测不仅要识别图片中有什么物体，还要确定目标的位置并用bounding box框出来。
这需要训练两个模型，一个classifer用于目标分类，一个regresser用于框出bounding box。
实现目标检测的方法有许多，其中主流的有r-cnn, fast-cnn, yolo。
因为目标检测算法需要用在在线检测中，所以识别的精度和速度都很重要。
传统的滑窗方法先建立位置大小不同的窗口，再再每个窗口中运行目标分类。而这些方法只需运行一次神经网络的运算，在feature map中找出可能包含目标的区域。
在初步识别之后，结果中会出现重复区域，需要用到nonmax supression将重复区域删除。
首先找到最可能包含目标的边框，然后计算最可能边框与其他边框的IOU（Intersection over Uniion）, IOU的值越大表示重复区域越多。最后滤除IOU小于阈值的边框就得到最终的边框。

### 3.2 语义分割

语义分割，图像信息像素信息（255，255,0）并不知道像素的含义，语义分割的目的是图片里信息的含义。
语义分割网络与图片分类不同的地方在于，分类网络最后一层是全连接层，语义分割网络是全卷积层，在feature map级别进行识别
主要应用可行使区域。车道线识别，车道不清晰，虚线，阴影，lanenet, 做车道线识别是先进行语义分割

### 3.3 传感器融合
摄像头的最大缺陷对深度的信息不是通过测量而是通过推测出来的。
摄像头虽然可以得到深度信息，但在特定的场景下会不准确。
而自动驾驶对安全的要求极高。其对性能的限制是以其最差情况为准。
因此最好的办法是扬长避短。将摄像头目标识别的优势与激光雷达、毫米波雷达测距，测速的优势结合起来。
具体方案可将，激光雷达的在三维坐标系中的点云投影到图像的二维平面上。
通过目标识别产生bounding box。再将bounding box内的点云与图像匹配生成目标。目标的类型由图像获得，目标的位置由激光雷达获得。最后再将目标与毫米波雷达进行匹配，获得速度信息。
因为毫米波雷达信号较为稀疏，所以采用目标级融合就可以。
而图像和激光雷达信号稠密，所以采用信号级融合。

## 4. 模型工程化

模型训练，到在控制器上移植，
工程化步骤，选择主干网络，修改top layer， 准备实验数据，工程化移植，验证的步骤
### 4.1 选择主干网络
第一步是根据要解决的问题选择主干网络。主干网络的目的是特征提取。
从神经网络的发展来看，
从12年8层的AlexNet，到14年22层的GoogLeNet，再到15年152层的ResNet,主干网络有层数增加的趋势。
但选择主干网络并不是层数越高越好。其中存在这性能与计算时间的有权衡关系。
如下图所示，精度越高的网络往往所需要的计算量也越大。
自动驾驶很多时候需要实时运算，所以可以选择像MobileNet这样计算量小性能又不错的网络结构。

### 4.2 修改上层网络
选择完底层网络，选择更改上层网络，如原来的网络在coco上训练的40多类，想做个真对道路目标的，将顶层改为6个，在用新数据集训练  

底层网络可以共用，底层特征类似。好处可以用少量数据就能训练，80% 的工作在底层特征，提高训练速度，减少训练数据。
pytorch, 选择主干网络，model zoo 可以下载训练过的网络。
选择训练数据
### 4.3 准备训练数据 
公开数据: Kitti, cityscape,nuscence, udacity, waymo
先验知识（如第一视角，结构化道路）
特殊场景，国内特有道路，工况
数据不足时可用采用数据扩充data augmentation
不好数据会降低模型精度
模型工程化
### 4.4 工程化移植
生态的重要性，tensorRT, 通用的结构onnx，对并行计算进行优化

### 4.5 感知架构设计
模块设计
子模块承担独立任务, 减少模块间通信，提高并行
子模块可以用深度学习（黑盒模型），通过大量数据充分验证其安全性
顶层模块采用相对简单的白盒模型，便于与人沟通
闭环，很大部分工作来自数据，20%工作来自修改模型，80%时间来自工具。
## 5. 总结
深度学习需要大量数据，pipeline，模型设计，部署，验证，数据采集的闭环
